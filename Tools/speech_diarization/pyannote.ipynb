{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1891473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6be8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0a482",
   "metadata": {},
   "source": [
    "# ğŸ™ï¸ Pyannote Speaker Diarization ì½”ë“œ ì„¤ëª…\n",
    "\n",
    "ì´ ì½”ë“œëŠ” Hugging Faceì˜ **pyannote.audio** ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬  \n",
    "ì˜¤ë””ì˜¤ íŒŒì¼(`audio.wav`)ì—ì„œ **í™”ì ë¶„ë¦¬(Speaker Diarization)**ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.  \n",
    "\n",
    "---\n",
    "\n",
    "## ì£¼ìš” íë¦„\n",
    "\n",
    "1. **í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°**\n",
    "   - `.env` íŒŒì¼ì— ì €ì¥ëœ `HUGGINGFACE_ACCESS_TOKEN`ì„ ë¶ˆëŸ¬ì™€ì„œ Hugging Face ëª¨ë¸ ì ‘ê·¼ì— ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. **Pipeline ë¡œë“œ**\n",
    "   - `pyannote/speaker-diarization-3.1` ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "   - ìµœì‹  ë²„ì „ì˜ `pyannote.audio`(3.x ê³„ì—´)ì—ì„œëŠ” `plda` ê°™ì€ íŒŒë¼ë¯¸í„°ëŠ” í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "   - GPU(CUDA)ê°€ ê°€ëŠ¥í•˜ë‹¤ë©´ ìë™ìœ¼ë¡œ GPUì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "\n",
    "3. **ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •**\n",
    "   - `os.getcwd()`ë¥¼ ì‚¬ìš©í•´ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì—ì„œ `audio.wav` íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "\n",
    "4. **Diarization ì‹¤í–‰**\n",
    "   - `pipeline(audio_file, hook=hook)`ì„ ì‹¤í–‰í•˜ë©´ í™”ì ë¶„ë¦¬ ê²°ê³¼(`Annotation` ê°ì²´)ê°€ ë°˜í™˜ë©ë‹ˆë‹¤.\n",
    "   - `ProgressHook`ì„ ì‚¬ìš©í•˜ë©´ ì§„í–‰ ìƒí™©ì´ í‘œì‹œë©ë‹ˆë‹¤.\n",
    "\n",
    "5. **ê²°ê³¼ ì¶œë ¥**\n",
    "   - ê²°ê³¼ëŠ” `output.itertracks(yield_label=True)`ë¡œ ìˆœíšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "   - ì—¬ê¸°ì„œ ê° ë³€ìˆ˜ì˜ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "---\n",
    "\n",
    "## ì¶œë ¥ êµ¬ì¡° ì„¤ëª…\n",
    "\n",
    "```python\n",
    "for turn, _, speaker in output.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "```\n",
    "\n",
    "-turn\n",
    "\n",
    "   -Segment ê°ì²´ (ì‹œì‘/ë ì‹œê°„ ì •ë³´ë¥¼ ë‹´ìŒ)\n",
    "\n",
    "   -ì˜ˆ: Segment(0.2, 1.5)\n",
    "\n",
    "   -ì ‘ê·¼: turn.start, turn.end\n",
    "\n",
    "_ (track id)\n",
    "\n",
    "   -ë™ì¼ speaker ì•ˆì—ì„œ ì—¬ëŸ¬ íŠ¸ë™ì„ êµ¬ë¶„í•  ë•Œ ì“°ì´ëŠ” ID\n",
    "\n",
    "   -íŠ¹ë³„íˆ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ _ë¡œ ë¬´ì‹œ\n",
    "\n",
    "-speaker\n",
    "\n",
    "   -í™”ì ë ˆì´ë¸” (ë¬¸ìì—´)\n",
    "\n",
    "   -ì˜ˆ: \"SPEAKER_00\", \"SPEAKER_01\"\n",
    "\n",
    "# ì˜ˆì‹œ ì¶œë ¥\n",
    "\n",
    "start=0.2s stop=1.5s speaker_SPEAKER_00\n",
    "\n",
    "start=1.8s stop=3.9s speaker_SPEAKER_01\n",
    "\n",
    "start=4.2s stop=5.7s speaker_SPEAKER_00\n",
    "\n",
    "\n",
    "ì¦‰, ì˜¤ë””ì˜¤ì˜ ê° êµ¬ê°„ë³„ë¡œ ì‹œì‘ì‹œê°„ / ì¢…ë£Œì‹œê°„ / í™”ìIDê°€ í‘œì‹œë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14fedf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì½”ë“œ íŒŒì¼ ê¸°ì¤€ ì ˆëŒ€ê²½ë¡œ\n",
    "#ì˜¤ë””ì˜¤ íŒŒì¼ ì´ë¦„\n",
    "AUDIO_PATH = \"data/audio.wav\"\n",
    "BASE_DIR = os.getcwd()\n",
    "# \n",
    "audio_file = os.path.join(BASE_DIR, AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a84ec3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844b323312174982870672def111098d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\SBA\\github\\test_syh\\sesacproject\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: \n",
       "UserWarning: std(): degrees of freedom is &lt;= 0. Correction should be strictly less than the reduction factor (input\n",
       "numel divided by output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1807.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\SBA\\github\\test_syh\\sesacproject\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: \n",
       "UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input\n",
       "numel divided by output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1807.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=8.7s stop=11.9s speaker_SPEAKER_03\n",
      "start=16.1s stop=40.1s speaker_SPEAKER_03\n",
      "start=40.8s stop=48.4s speaker_SPEAKER_00\n",
      "start=48.6s stop=56.5s speaker_SPEAKER_00\n",
      "start=57.0s stop=61.6s speaker_SPEAKER_00\n",
      "start=62.6s stop=71.6s speaker_SPEAKER_01\n",
      "start=72.2s stop=75.7s speaker_SPEAKER_01\n",
      "start=75.9s stop=80.6s speaker_SPEAKER_01\n",
      "start=81.2s stop=85.6s speaker_SPEAKER_01\n",
      "start=86.6s stop=99.3s speaker_SPEAKER_02\n",
      "start=99.9s stop=110.0s speaker_SPEAKER_02\n",
      "start=111.6s stop=118.3s speaker_SPEAKER_03\n",
      "start=118.9s stop=126.8s speaker_SPEAKER_03\n",
      "start=129.2s stop=137.0s speaker_SPEAKER_03\n",
      "start=137.4s stop=141.1s speaker_SPEAKER_03\n",
      "start=142.1s stop=150.6s speaker_SPEAKER_00\n",
      "start=151.3s stop=155.7s speaker_SPEAKER_01\n",
      "start=156.2s stop=160.4s speaker_SPEAKER_01\n",
      "start=161.4s stop=165.9s speaker_SPEAKER_01\n",
      "start=167.3s stop=176.0s speaker_SPEAKER_02\n",
      "start=176.2s stop=184.3s speaker_SPEAKER_02\n",
      "start=186.0s stop=213.0s speaker_SPEAKER_03\n",
      "start=214.4s stop=215.1s speaker_SPEAKER_03\n",
      "start=215.1s stop=216.7s speaker_SPEAKER_03\n",
      "start=217.6s stop=219.5s speaker_SPEAKER_00\n",
      "start=219.6s stop=223.7s speaker_SPEAKER_00\n",
      "start=224.4s stop=227.8s speaker_SPEAKER_01\n",
      "start=228.3s stop=232.0s speaker_SPEAKER_02\n",
      "start=233.1s stop=240.9s speaker_SPEAKER_03\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN\")\n",
    "#print(\"HF_TOKEN:\", HF_TOKEN)\n",
    "\n",
    "# Community-1 open-source speaker diarization pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=HF_TOKEN\n",
    ")\n",
    "\n",
    "# CUDAê°€ ìˆìœ¼ë©´ GPU, ì—†ìœ¼ë©´ CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline.to(device)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "with ProgressHook() as hook:\n",
    "    output = pipeline(audio_file, hook=hook)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for turn, _, speaker in output.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyannote.audio import Pipeline\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ==============================\n",
    "# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "# ==============================\n",
    "load_dotenv()\n",
    "PYANNOTE_TOKEN = os.getenv(\"PYANNOTEAI_API_KEY\")\n",
    "\n",
    "if not PYANNOTE_TOKEN:\n",
    "    raise ValueError(\"í™˜ê²½ ë³€ìˆ˜ì— PYANNOTEAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ==============================\n",
    "# 2. Precision-2 Speaker Diarization (ì„œë²„ ì‹¤í–‰)\n",
    "# ==============================\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-precision-2\",\n",
    "    token=PYANNOTE_TOKEN\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 3. ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ\n",
    "# ==============================\n",
    "audio_file = os.path.join(\"data\", \"tiro_Test1_4People.wav\")\n",
    "\n",
    "# ==============================\n",
    "# 4. ì‹¤í–‰ (ì„œë²„ì—ì„œ ì²˜ë¦¬)\n",
    "# ==============================\n",
    "output = pipeline(audio_file)  # pyannoteAI ì„œë²„ì—ì„œ ì‹¤í–‰ë¨\n",
    "\n",
    "# ==============================\n",
    "# 5. ê²°ê³¼ ì¶œë ¥\n",
    "# ==============================\n",
    "for turn, speaker in output.speaker_diarization:\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s {speaker}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesacproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
