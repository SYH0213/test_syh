{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1891473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6be8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0a482",
   "metadata": {},
   "source": [
    "# 🎙️ Pyannote Speaker Diarization 코드 설명\n",
    "\n",
    "이 코드는 Hugging Face의 **pyannote.audio** 라이브러리를 사용하여  \n",
    "오디오 파일(`audio.wav`)에서 **화자 분리(Speaker Diarization)**를 수행하는 예제입니다.  \n",
    "\n",
    "---\n",
    "\n",
    "## 주요 흐름\n",
    "\n",
    "1. **환경 변수 불러오기**\n",
    "   - `.env` 파일에 저장된 `HUGGINGFACE_ACCESS_TOKEN`을 불러와서 Hugging Face 모델 접근에 사용합니다.\n",
    "\n",
    "2. **Pipeline 로드**\n",
    "   - `pyannote/speaker-diarization-3.1` 모델을 불러옵니다.\n",
    "   - 최신 버전의 `pyannote.audio`(3.x 계열)에서는 `plda` 같은 파라미터는 필요하지 않습니다.\n",
    "   - GPU(CUDA)가 가능하다면 자동으로 GPU에서 실행됩니다.\n",
    "\n",
    "3. **오디오 파일 경로 설정**\n",
    "   - `os.getcwd()`를 사용해 현재 작업 디렉토리에서 `audio.wav` 파일을 불러옵니다.\n",
    "\n",
    "4. **Diarization 실행**\n",
    "   - `pipeline(audio_file, hook=hook)`을 실행하면 화자 분리 결과(`Annotation` 객체)가 반환됩니다.\n",
    "   - `ProgressHook`을 사용하면 진행 상황이 표시됩니다.\n",
    "\n",
    "5. **결과 출력**\n",
    "   - 결과는 `output.itertracks(yield_label=True)`로 순회할 수 있습니다.\n",
    "   - 여기서 각 변수의 의미는 다음과 같습니다:\n",
    "\n",
    "---\n",
    "\n",
    "## 출력 구조 설명\n",
    "\n",
    "```python\n",
    "for turn, _, speaker in output.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "```\n",
    "\n",
    "-turn\n",
    "\n",
    "   -Segment 객체 (시작/끝 시간 정보를 담음)\n",
    "\n",
    "   -예: Segment(0.2, 1.5)\n",
    "\n",
    "   -접근: turn.start, turn.end\n",
    "\n",
    "_ (track id)\n",
    "\n",
    "   -동일 speaker 안에서 여러 트랙을 구분할 때 쓰이는 ID\n",
    "\n",
    "   -특별히 사용하지 않으므로 _로 무시\n",
    "\n",
    "-speaker\n",
    "\n",
    "   -화자 레이블 (문자열)\n",
    "\n",
    "   -예: \"SPEAKER_00\", \"SPEAKER_01\"\n",
    "\n",
    "# 예시 출력\n",
    "\n",
    "start=0.2s stop=1.5s speaker_SPEAKER_00\n",
    "\n",
    "start=1.8s stop=3.9s speaker_SPEAKER_01\n",
    "\n",
    "start=4.2s stop=5.7s speaker_SPEAKER_00\n",
    "\n",
    "\n",
    "즉, 오디오의 각 구간별로 시작시간 / 종료시간 / 화자ID가 표시됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fedf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 현재 실행 중인 코드 파일 기준 절대경로\n",
    "#오디오 파일 이름\n",
    "AUDIO_PATH = \"data/CabinetMeeting_economy_5p_12m_low.wav\"\n",
    "BASE_DIR = os.getcwd()\n",
    "# \n",
    "audio_file = os.path.join(BASE_DIR, AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f605a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\손용훈\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:992: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN\")\n",
    "#print(\"HF_TOKEN:\", HF_TOKEN)\n",
    "\n",
    "# Community-1 open-source speaker diarization pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b2ad8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n",
      "NVIDIA GeForce RTX 3050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())       # True\n",
    "print(torch.version.cuda)              # 11.8 또는 12.1\n",
    "print(torch.cuda.get_device_name(0))   # GPU 이름\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a84ec3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41739ba68c646389ef7ba905fe550de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">e:\\github\\Module\\sesacproject\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): \n",
       "degrees of freedom is &lt;= 0. Correction should be strictly less than the reduction factor (input numel divided by \n",
       "output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1807.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "e:\\github\\Module\\sesacproject\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): \n",
       "degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by \n",
       "output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1807.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.0s stop=1.0s speaker_SPEAKER_04\n",
      "start=1.0s stop=1.4s speaker_SPEAKER_00\n",
      "start=1.7s stop=12.6s speaker_SPEAKER_00\n",
      "start=11.5s stop=13.4s speaker_SPEAKER_04\n",
      "start=13.4s stop=19.3s speaker_SPEAKER_00\n",
      "start=19.3s stop=21.4s speaker_SPEAKER_04\n",
      "start=22.1s stop=38.9s speaker_SPEAKER_00\n",
      "start=39.3s stop=41.8s speaker_SPEAKER_04\n",
      "start=42.8s stop=45.1s speaker_SPEAKER_04\n",
      "start=46.0s stop=48.4s speaker_SPEAKER_04\n",
      "start=49.3s stop=53.3s speaker_SPEAKER_04\n",
      "start=54.7s stop=59.1s speaker_SPEAKER_04\n",
      "start=61.2s stop=62.2s speaker_SPEAKER_04\n",
      "start=62.4s stop=64.6s speaker_SPEAKER_04\n",
      "start=64.9s stop=69.2s speaker_SPEAKER_00\n",
      "start=69.1s stop=69.5s speaker_SPEAKER_04\n",
      "start=69.5s stop=70.1s speaker_SPEAKER_00\n",
      "start=70.1s stop=78.6s speaker_SPEAKER_04\n",
      "start=75.3s stop=75.8s speaker_SPEAKER_00\n",
      "start=76.5s stop=76.5s speaker_SPEAKER_00\n",
      "start=76.6s stop=76.6s speaker_SPEAKER_00\n",
      "start=79.3s stop=82.0s speaker_SPEAKER_04\n",
      "start=82.5s stop=84.2s speaker_SPEAKER_00\n",
      "start=85.0s stop=89.2s speaker_SPEAKER_04\n",
      "start=90.4s stop=92.1s speaker_SPEAKER_04\n",
      "start=92.1s stop=92.1s speaker_SPEAKER_00\n",
      "start=92.4s stop=92.4s speaker_SPEAKER_00\n",
      "start=92.4s stop=92.4s speaker_SPEAKER_04\n",
      "start=92.4s stop=92.6s speaker_SPEAKER_00\n",
      "start=92.6s stop=92.6s speaker_SPEAKER_04\n",
      "start=92.6s stop=93.1s speaker_SPEAKER_00\n",
      "start=96.6s stop=120.9s speaker_SPEAKER_05\n",
      "start=120.9s stop=125.8s speaker_SPEAKER_04\n",
      "start=126.5s stop=136.8s speaker_SPEAKER_04\n",
      "start=137.0s stop=141.3s speaker_SPEAKER_04\n",
      "start=141.3s stop=151.1s speaker_SPEAKER_05\n",
      "start=151.1s stop=152.2s speaker_SPEAKER_04\n",
      "start=152.3s stop=156.1s speaker_SPEAKER_04\n",
      "start=156.2s stop=162.3s speaker_SPEAKER_00\n",
      "start=162.3s stop=163.7s speaker_SPEAKER_04\n",
      "start=163.3s stop=177.2s speaker_SPEAKER_00\n",
      "start=177.0s stop=180.3s speaker_SPEAKER_04\n",
      "start=180.8s stop=183.6s speaker_SPEAKER_04\n",
      "start=184.2s stop=185.5s speaker_SPEAKER_04\n",
      "start=185.4s stop=186.0s speaker_SPEAKER_00\n",
      "start=187.0s stop=189.3s speaker_SPEAKER_04\n",
      "start=189.4s stop=256.3s speaker_SPEAKER_00\n",
      "start=256.3s stop=269.1s speaker_SPEAKER_04\n",
      "start=269.3s stop=271.3s speaker_SPEAKER_04\n",
      "start=272.4s stop=272.4s speaker_SPEAKER_04\n",
      "start=272.4s stop=302.0s speaker_SPEAKER_05\n",
      "start=302.0s stop=304.1s speaker_SPEAKER_04\n",
      "start=304.8s stop=319.3s speaker_SPEAKER_04\n",
      "start=319.7s stop=322.2s speaker_SPEAKER_04\n",
      "start=322.2s stop=331.6s speaker_SPEAKER_05\n",
      "start=328.0s stop=328.7s speaker_SPEAKER_02\n",
      "start=328.7s stop=328.7s speaker_SPEAKER_04\n",
      "start=331.6s stop=331.6s speaker_SPEAKER_02\n",
      "start=331.6s stop=332.2s speaker_SPEAKER_05\n",
      "start=332.2s stop=359.7s speaker_SPEAKER_02\n",
      "start=356.4s stop=358.4s speaker_SPEAKER_04\n",
      "start=359.8s stop=365.8s speaker_SPEAKER_02\n",
      "start=365.8s stop=369.2s speaker_SPEAKER_04\n",
      "start=369.2s stop=370.8s speaker_SPEAKER_05\n",
      "start=370.6s stop=371.1s speaker_SPEAKER_03\n",
      "start=370.8s stop=370.8s speaker_SPEAKER_02\n",
      "start=371.4s stop=371.4s speaker_SPEAKER_03\n",
      "start=371.4s stop=430.5s speaker_SPEAKER_05\n",
      "start=371.5s stop=371.7s speaker_SPEAKER_03\n",
      "start=431.6s stop=437.3s speaker_SPEAKER_05\n",
      "start=438.2s stop=444.0s speaker_SPEAKER_05\n",
      "start=444.0s stop=444.5s speaker_SPEAKER_04\n",
      "start=444.5s stop=444.5s speaker_SPEAKER_05\n",
      "start=444.5s stop=464.0s speaker_SPEAKER_04\n",
      "start=445.7s stop=446.5s speaker_SPEAKER_05\n",
      "start=454.3s stop=454.8s speaker_SPEAKER_05\n",
      "start=462.4s stop=464.1s speaker_SPEAKER_05\n",
      "start=464.5s stop=466.0s speaker_SPEAKER_04\n",
      "start=466.0s stop=494.0s speaker_SPEAKER_05\n",
      "start=491.4s stop=491.9s speaker_SPEAKER_04\n",
      "start=494.3s stop=497.4s speaker_SPEAKER_05\n",
      "start=496.8s stop=497.0s speaker_SPEAKER_04\n",
      "start=497.2s stop=497.3s speaker_SPEAKER_04\n",
      "start=497.4s stop=497.6s speaker_SPEAKER_04\n",
      "start=497.6s stop=497.7s speaker_SPEAKER_05\n",
      "start=497.7s stop=497.7s speaker_SPEAKER_04\n",
      "start=497.7s stop=497.9s speaker_SPEAKER_04\n",
      "start=497.9s stop=497.9s speaker_SPEAKER_05\n",
      "start=498.8s stop=501.7s speaker_SPEAKER_04\n",
      "start=502.3s stop=505.1s speaker_SPEAKER_04\n",
      "start=505.5s stop=510.6s speaker_SPEAKER_04\n",
      "start=511.6s stop=516.2s speaker_SPEAKER_04\n",
      "start=512.7s stop=512.9s speaker_SPEAKER_02\n",
      "start=512.9s stop=512.9s speaker_SPEAKER_00\n",
      "start=512.9s stop=512.9s speaker_SPEAKER_03\n",
      "start=512.9s stop=513.0s speaker_SPEAKER_00\n",
      "start=517.5s stop=520.4s speaker_SPEAKER_04\n",
      "start=521.4s stop=523.2s speaker_SPEAKER_04\n",
      "start=523.2s stop=566.7s speaker_SPEAKER_00\n",
      "start=566.6s stop=580.5s speaker_SPEAKER_04\n",
      "start=581.4s stop=582.2s speaker_SPEAKER_04\n",
      "start=583.7s stop=588.2s speaker_SPEAKER_04\n",
      "start=588.2s stop=594.5s speaker_SPEAKER_00\n",
      "start=594.5s stop=598.8s speaker_SPEAKER_04\n",
      "start=599.8s stop=601.1s speaker_SPEAKER_04\n",
      "start=602.1s stop=608.5s speaker_SPEAKER_04\n",
      "start=609.1s stop=616.0s speaker_SPEAKER_04\n",
      "start=617.5s stop=655.1s speaker_SPEAKER_05\n",
      "start=655.1s stop=666.2s speaker_SPEAKER_04\n",
      "start=667.6s stop=668.2s speaker_SPEAKER_04\n",
      "start=668.7s stop=674.9s speaker_SPEAKER_01\n",
      "start=675.3s stop=683.8s speaker_SPEAKER_01\n",
      "start=683.9s stop=685.0s speaker_SPEAKER_01\n",
      "start=685.0s stop=685.0s speaker_SPEAKER_00\n",
      "start=685.0s stop=685.0s speaker_SPEAKER_01\n",
      "start=685.0s stop=685.0s speaker_SPEAKER_04\n",
      "start=685.2s stop=691.2s speaker_SPEAKER_04\n",
      "start=692.8s stop=694.6s speaker_SPEAKER_04\n",
      "start=695.7s stop=704.1s speaker_SPEAKER_04\n",
      "start=704.1s stop=727.0s speaker_SPEAKER_03\n",
      "start=720.8s stop=720.9s speaker_SPEAKER_04\n",
      "start=727.0s stop=727.9s speaker_SPEAKER_04\n",
      "start=727.9s stop=728.0s speaker_SPEAKER_03\n",
      "start=728.7s stop=728.8s speaker_SPEAKER_03\n",
      "start=728.8s stop=739.5s speaker_SPEAKER_04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# CUDA가 있으면 GPU, 없으면 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline.to(device)\n",
    "\n",
    "# 실행\n",
    "with ProgressHook() as hook:\n",
    "    output = pipeline(audio_file, hook=hook)\n",
    "\n",
    "# 결과 출력\n",
    "for turn, _, speaker in output.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c3db7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0aca61a1d64fc3850b72e9a56fe5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">e:\\github\\Module\\sesacproject\\Lib\\site-packages\\pyannote\\audio\\utils\\reproducibility.py:74: ReproducibilityWarning:\n",
       "TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
       "It can be re-enabled by calling\n",
       "   &gt;&gt;&gt; import torch\n",
       "   &gt;&gt;&gt; torch.backends.cuda.matmul.allow_tf32 = True\n",
       "   &gt;&gt;&gt; torch.backends.cudnn.allow_tf32 = True\n",
       "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
       "\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "e:\\github\\Module\\sesacproject\\Lib\\site-packages\\pyannote\\audio\\utils\\reproducibility.py:74: ReproducibilityWarning:\n",
       "TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
       "It can be re-enabled by calling\n",
       "   >>> import torch\n",
       "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
       "   >>> torch.backends.cudnn.allow_tf32 = True\n",
       "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
       "\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">e:\\github\\Module\\sesacproject\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): \n",
       "degrees of freedom is &lt;= 0. Correction should be strictly less than the reduction factor (input numel divided by \n",
       "output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1807.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "e:\\github\\Module\\sesacproject\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): \n",
       "degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by \n",
       "output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1807.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.0s stop=1.0s speaker_SPEAKER_04\n",
      "start=1.0s stop=1.4s speaker_SPEAKER_00\n",
      "start=1.7s stop=12.6s speaker_SPEAKER_00\n",
      "start=11.5s stop=13.4s speaker_SPEAKER_04\n",
      "start=13.4s stop=19.3s speaker_SPEAKER_00\n",
      "start=19.3s stop=21.4s speaker_SPEAKER_04\n",
      "start=22.1s stop=38.9s speaker_SPEAKER_00\n",
      "start=39.3s stop=41.8s speaker_SPEAKER_04\n",
      "start=42.8s stop=45.1s speaker_SPEAKER_04\n",
      "start=46.0s stop=48.4s speaker_SPEAKER_04\n",
      "start=49.3s stop=53.3s speaker_SPEAKER_04\n",
      "start=54.7s stop=59.1s speaker_SPEAKER_04\n",
      "start=61.2s stop=62.2s speaker_SPEAKER_04\n",
      "start=62.4s stop=64.6s speaker_SPEAKER_04\n",
      "start=64.9s stop=69.2s speaker_SPEAKER_00\n",
      "start=69.1s stop=69.5s speaker_SPEAKER_04\n",
      "start=69.5s stop=70.1s speaker_SPEAKER_00\n",
      "start=70.1s stop=78.6s speaker_SPEAKER_04\n",
      "start=75.3s stop=75.8s speaker_SPEAKER_00\n",
      "start=76.5s stop=76.5s speaker_SPEAKER_00\n",
      "start=76.6s stop=76.6s speaker_SPEAKER_00\n",
      "start=79.3s stop=82.0s speaker_SPEAKER_04\n",
      "start=82.5s stop=84.2s speaker_SPEAKER_00\n",
      "start=85.0s stop=89.2s speaker_SPEAKER_04\n",
      "start=90.4s stop=92.1s speaker_SPEAKER_04\n",
      "start=92.1s stop=92.1s speaker_SPEAKER_00\n",
      "start=92.4s stop=92.4s speaker_SPEAKER_00\n",
      "start=92.4s stop=92.4s speaker_SPEAKER_04\n",
      "start=92.4s stop=92.6s speaker_SPEAKER_00\n",
      "start=92.6s stop=92.6s speaker_SPEAKER_04\n",
      "start=92.6s stop=93.1s speaker_SPEAKER_00\n",
      "start=96.6s stop=120.9s speaker_SPEAKER_05\n",
      "start=120.9s stop=125.8s speaker_SPEAKER_04\n",
      "start=126.5s stop=136.8s speaker_SPEAKER_04\n",
      "start=137.0s stop=141.3s speaker_SPEAKER_04\n",
      "start=141.3s stop=151.1s speaker_SPEAKER_05\n",
      "start=151.1s stop=152.2s speaker_SPEAKER_04\n",
      "start=152.3s stop=156.1s speaker_SPEAKER_04\n",
      "start=156.2s stop=162.3s speaker_SPEAKER_00\n",
      "start=162.3s stop=163.7s speaker_SPEAKER_04\n",
      "start=163.3s stop=177.2s speaker_SPEAKER_00\n",
      "start=177.0s stop=180.3s speaker_SPEAKER_04\n",
      "start=180.8s stop=183.6s speaker_SPEAKER_04\n",
      "start=184.2s stop=185.5s speaker_SPEAKER_04\n",
      "start=185.4s stop=186.0s speaker_SPEAKER_00\n",
      "start=187.0s stop=189.3s speaker_SPEAKER_04\n",
      "start=189.4s stop=256.3s speaker_SPEAKER_00\n",
      "start=256.3s stop=269.1s speaker_SPEAKER_04\n",
      "start=269.3s stop=271.3s speaker_SPEAKER_04\n",
      "start=272.4s stop=272.4s speaker_SPEAKER_04\n",
      "start=272.4s stop=302.0s speaker_SPEAKER_05\n",
      "start=302.0s stop=304.1s speaker_SPEAKER_04\n",
      "start=304.8s stop=319.3s speaker_SPEAKER_04\n",
      "start=319.7s stop=322.2s speaker_SPEAKER_04\n",
      "start=322.2s stop=331.6s speaker_SPEAKER_05\n",
      "start=328.0s stop=328.7s speaker_SPEAKER_02\n",
      "start=328.7s stop=328.7s speaker_SPEAKER_04\n",
      "start=331.6s stop=331.6s speaker_SPEAKER_02\n",
      "start=331.6s stop=332.2s speaker_SPEAKER_05\n",
      "start=332.2s stop=359.7s speaker_SPEAKER_02\n",
      "start=356.4s stop=358.4s speaker_SPEAKER_04\n",
      "start=359.8s stop=365.8s speaker_SPEAKER_02\n",
      "start=365.8s stop=369.2s speaker_SPEAKER_04\n",
      "start=369.2s stop=370.8s speaker_SPEAKER_05\n",
      "start=370.6s stop=371.1s speaker_SPEAKER_03\n",
      "start=370.8s stop=370.8s speaker_SPEAKER_02\n",
      "start=371.4s stop=371.4s speaker_SPEAKER_03\n",
      "start=371.4s stop=430.5s speaker_SPEAKER_05\n",
      "start=371.5s stop=371.7s speaker_SPEAKER_03\n",
      "start=431.6s stop=437.3s speaker_SPEAKER_05\n",
      "start=438.2s stop=444.0s speaker_SPEAKER_05\n",
      "start=444.0s stop=444.5s speaker_SPEAKER_04\n",
      "start=444.5s stop=444.5s speaker_SPEAKER_05\n",
      "start=444.5s stop=464.0s speaker_SPEAKER_04\n",
      "start=445.7s stop=446.5s speaker_SPEAKER_05\n",
      "start=454.3s stop=454.8s speaker_SPEAKER_05\n",
      "start=462.4s stop=464.1s speaker_SPEAKER_05\n",
      "start=464.5s stop=466.0s speaker_SPEAKER_04\n",
      "start=466.0s stop=494.0s speaker_SPEAKER_05\n",
      "start=491.4s stop=491.9s speaker_SPEAKER_04\n",
      "start=494.3s stop=497.4s speaker_SPEAKER_05\n",
      "start=496.8s stop=497.0s speaker_SPEAKER_04\n",
      "start=497.2s stop=497.3s speaker_SPEAKER_04\n",
      "start=497.4s stop=497.6s speaker_SPEAKER_04\n",
      "start=497.6s stop=497.7s speaker_SPEAKER_05\n",
      "start=497.7s stop=497.7s speaker_SPEAKER_04\n",
      "start=497.7s stop=497.9s speaker_SPEAKER_04\n",
      "start=497.9s stop=497.9s speaker_SPEAKER_05\n",
      "start=498.8s stop=501.7s speaker_SPEAKER_04\n",
      "start=502.3s stop=505.1s speaker_SPEAKER_04\n",
      "start=505.5s stop=510.6s speaker_SPEAKER_04\n",
      "start=511.6s stop=516.2s speaker_SPEAKER_04\n",
      "start=512.7s stop=512.9s speaker_SPEAKER_02\n",
      "start=512.9s stop=512.9s speaker_SPEAKER_00\n",
      "start=512.9s stop=512.9s speaker_SPEAKER_03\n",
      "start=512.9s stop=513.0s speaker_SPEAKER_00\n",
      "start=517.5s stop=520.4s speaker_SPEAKER_04\n",
      "start=521.4s stop=523.2s speaker_SPEAKER_04\n",
      "start=523.2s stop=566.7s speaker_SPEAKER_00\n",
      "start=566.6s stop=580.5s speaker_SPEAKER_04\n",
      "start=581.4s stop=582.2s speaker_SPEAKER_04\n",
      "start=583.7s stop=588.2s speaker_SPEAKER_04\n",
      "start=588.2s stop=594.5s speaker_SPEAKER_00\n",
      "start=594.5s stop=598.8s speaker_SPEAKER_04\n",
      "start=599.8s stop=601.1s speaker_SPEAKER_04\n",
      "start=602.1s stop=608.5s speaker_SPEAKER_04\n",
      "start=609.1s stop=616.0s speaker_SPEAKER_04\n",
      "start=617.5s stop=655.1s speaker_SPEAKER_05\n",
      "start=655.1s stop=666.2s speaker_SPEAKER_04\n",
      "start=667.6s stop=668.2s speaker_SPEAKER_04\n",
      "start=668.7s stop=674.9s speaker_SPEAKER_01\n",
      "start=675.3s stop=683.8s speaker_SPEAKER_01\n",
      "start=683.9s stop=685.0s speaker_SPEAKER_01\n",
      "start=685.0s stop=685.0s speaker_SPEAKER_00\n",
      "start=685.0s stop=685.0s speaker_SPEAKER_01\n",
      "start=685.0s stop=685.0s speaker_SPEAKER_04\n",
      "start=685.2s stop=691.2s speaker_SPEAKER_04\n",
      "start=692.8s stop=694.6s speaker_SPEAKER_04\n",
      "start=695.7s stop=704.1s speaker_SPEAKER_04\n",
      "start=704.1s stop=727.0s speaker_SPEAKER_03\n",
      "start=720.8s stop=720.9s speaker_SPEAKER_04\n",
      "start=727.0s stop=727.9s speaker_SPEAKER_04\n",
      "start=727.9s stop=728.0s speaker_SPEAKER_03\n",
      "start=728.7s stop=728.8s speaker_SPEAKER_03\n",
      "start=728.8s stop=739.5s speaker_SPEAKER_04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# CUDA가 있으면 GPU, 없으면 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline.to(device)\n",
    "\n",
    "# 실행\n",
    "with ProgressHook() as hook:\n",
    "    output = pipeline(audio_file, hook=hook)\n",
    "\n",
    "# 결과 출력\n",
    "for turn, _, speaker in output.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35011b",
   "metadata": {},
   "source": [
    "## API 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyannote.audio import Pipeline\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ==============================\n",
    "# 1. 환경 변수 로드\n",
    "# ==============================\n",
    "load_dotenv()\n",
    "PYANNOTE_TOKEN = os.getenv(\"PYANNOTEAI_API_KEY\")\n",
    "\n",
    "if not PYANNOTE_TOKEN:\n",
    "    raise ValueError(\"환경 변수에 PYANNOTEAI_API_KEY가 없습니다. .env 파일을 확인하세요.\")\n",
    "\n",
    "# ==============================\n",
    "# 2. Precision-2 Speaker Diarization (서버 실행)\n",
    "# ==============================\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-precision-2\",\n",
    "    token=PYANNOTE_TOKEN\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 3. 오디오 파일 경로\n",
    "# ==============================\n",
    "audio_file = os.path.join(\"data\", \"tiro_Test1_4People.wav\")\n",
    "\n",
    "# ==============================\n",
    "# 4. 실행 (서버에서 처리)\n",
    "# ==============================\n",
    "output = pipeline(audio_file)  # pyannoteAI 서버에서 실행됨\n",
    "\n",
    "# ==============================\n",
    "# 5. 결과 출력\n",
    "# ==============================\n",
    "for turn, speaker in output.speaker_diarization:\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s {speaker}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesacproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
