"""
[ai-seong-han-juni]
ì´ íŒŒì¼ì€ UI íŒ€ì˜ 'ì•ˆë‚´ ë°ìŠ¤í¬ ì§ì›' ì—­í• ì„ í•©ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ í™”ë©´ì—ì„œ ë²„íŠ¼ì„ ëˆ„ë¥´ê±°ë‚˜, íŒŒì¼ì„ ì„ íƒí•˜ëŠ” ë“± ì–´ë–¤ í–‰ë™ì„ í–ˆì„ ë•Œ,
ê·¸ í–‰ë™ì— ë§ì¶° ì‹¤ì œ ê¸°ëŠ¥ì„ ì‹¤í–‰í•˜ëŠ” ì¼ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, 'ì²˜ë¦¬ ì‹œì‘' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ 'í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €'ì—ê²Œ íšŒì˜ë¡ ì²˜ë¦¬ë¥¼ ì§€ì‹œí•˜ê³ ,
ê·¸ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ í™”ë©´ì— ìš”ì•½ë³¸ì´ë‚˜ ëŒ€í™”ë¡ì„ ë³´ì—¬ì£¼ëŠ” ì‹ì´ì£ .
"""
# -*- coding: utf-8 -*-
import gradio as gr
import os
import logging
import re
import uuid
import json
from slugify import slugify

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from ..pipelines.main_pipeline import run_pipeline
from ..settings import (
    AUDIO_INPUT_DIR_NAME,
    RESULTS_DIR_NAME,
    AVAILABLE_LLMS,
    DEFAULT_MEETING_TOPIC,
    DEFAULT_KEYWORDS
)
from .handlers import (
    get_audio_files_for_df,
    get_audio_files_for_dropdown,
    refresh_audio_dropdown,
    upload_file,
    save_recording
)
from ..chatbot.graph import run_query

# --- ê¸°ë³¸ ì„¤ì • ---
# í”„ë¡œì íŠ¸ì˜ ì¤‘ìš”í•œ í´ë” ìœ„ì¹˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_DIR = os.path.join(ROOT_DIR, AUDIO_INPUT_DIR_NAME)
RESULTS_DIR = os.path.join(ROOT_DIR, RESULTS_DIR_NAME)

# --- UI í—¬í¼ í•¨ìˆ˜ ---

def create_zoom_link(url):
    """Zoom ë§í¬ë¥¼ ë°›ì•„ì„œ í´ë¦­ ê°€ëŠ¥í•œ ë§ˆí¬ë‹¤ìš´ ë§í¬ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    if url and "zoom.us" in url:
        return gr.Markdown(f">â¡ï¸ <a href='{url}' target='_blank' style='color: blue; text-decoration: underline;'>í´ë¦­í•˜ì—¬ Zoom íšŒì˜ ì—´ê¸°</a>")
    elif not url:
        return gr.Markdown("")
    return gr.Markdown("<span style='color: red;'>ìœ íš¨í•œ Zoom íšŒì˜ ë§í¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.</span>")

def get_processed_meetings():
    """ì²˜ë¦¬ëœ íšŒì˜ë¡ ëª©ë¡ì„ ìŠ¤ìº”í•˜ì—¬ ë“œë¡­ë‹¤ìš´ìš©ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    processed_meetings = []
    if not os.path.exists(RESULTS_DIR):
        return processed_meetings

    for folder_name in os.listdir(RESULTS_DIR):
        folder_path = os.path.join(RESULTS_DIR, folder_name)
        if os.path.isdir(folder_path):
            base_filename = '_'.join(folder_name.split('_')[:-1])
            corrected_file = f"corrected_{base_filename}.txt"
            if os.path.exists(os.path.join(folder_path, corrected_file)):
                # 1. Transliterate base_filename to an ASCII slug
                slugified_name = slugify(base_filename, separator='_', lowercase=True, replacements=[['.', '_']])
                # 2. Apply final sanitization (ChromaDB specific) - remove any remaining non-allowed chars
                collection_name = re.sub(r'[^a-zA-Z0-9._-]', '_', slugified_name)

                # 3. Ensure collection_name meets ChromaDB's rules (min 3 chars, starts/ends with alphanumeric)
                # Remove leading/trailing underscores that might violate start/end rule
                collection_name = collection_name.strip('_')
                
                # If it became empty after stripping, or is too short, use a fallback
                if not collection_name or len(collection_name) < 3:
                    # Fallback to a sanitized version of the full folder_name if base_filename is too short/empty
                    temp_name = slugify(folder_name, separator='_', lowercase=True, replacements=[['.', '_']])
                    temp_name = re.sub(r'[^a-zA-Z0-9._-]', '_', temp_name).strip('_')
                    if len(temp_name) >= 3:
                        collection_name = temp_name
                    else:
                        # Last resort: generate a unique, valid name
                        collection_name = "meeting_" + str(uuid.uuid4())[:8].replace('-', '_') # Ensure it's always valid and long enough
                processed_meetings.append((folder_name, collection_name))
    
    return sorted(processed_meetings, key=lambda x: x[0], reverse=True)

def format_summary_json_to_markdown(summary_json_str: str) -> str:
    """
    ìš”ì•½ ê²°ê³¼ì¸ JSON ë¬¸ìì—´ì„ ì‚¬ìš©ìê°€ ë³´ê¸° ì¢‹ì€ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if not summary_json_str or "ìš”ì•½ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." in summary_json_str:
        return "ìš”ì•½ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

    try:
        # LLMì˜ ì‘ë‹µì— í¬í•¨ë  ìˆ˜ ìˆëŠ” ë¹„-JSON í…ìŠ¤íŠ¸(ì˜ˆ: ì„¤ëª…, ì½”ë“œ ë¸”ë¡ ë§ˆì»¤)ë¥¼ ì •ë¦¬
        json_start_index = summary_json_str.find('{')
        json_end_index = summary_json_str.rfind('}')
        if json_start_index == -1 or json_end_index == -1:
            return summary_json_str # JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜

        summary_json_str = summary_json_str[json_start_index:json_end_index+1]
        data = json.loads(summary_json_str)
        
        md = ""

        if data.get("decisions"):
            md += "### ì£¼ìš” ê²°ì •ì‚¬í•­\n"
            for item in data["decisions"]:
                md += f"- {item.get('text', 'N/A')}\n"
            md += "\n"

        if data.get("action_items"):
            md += "### Action Items\n"
            for item in data["action_items"]:
                assignee = item.get('assignee', 'ë¯¸ì§€ì •')
                task = item.get('task', 'N/A')
                due = f" (ê¸°í•œ: {item.get('due')})" if item.get('due') else ""
                md += f"- **{assignee}**: {task}{due}\n"
            md += "\n"

        if data.get("key_points"):
            md += "### í•µì‹¬ ë…¼ì˜\n"
            for item in data["key_points"]:
                topic = item.get('topic', 'ì†Œì£¼ì œ ì—†ìŒ')
                summary_text = item.get('summary', 'N/A')
                md += f"- **({topic})**: {summary_text}\n"
            md += "\n"
        
        return md if md else "ìš”ì•½ ë‚´ìš©ì—ì„œ í‘œì‹œí•  í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    except json.JSONDecodeError:
        logging.error(f"ìš”ì•½ ë‚´ìš© JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return summary_json_str
    except Exception as e:
        logging.error(f"ìš”ì•½ ë‚´ìš© ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return f"ìš”ì•½ ë‚´ìš©ì„ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --- Gradio ì½œë°± ë˜í¼ í•¨ìˆ˜ (ui.handlersì˜ í•¨ìˆ˜ë“¤ì„ Gradioì— ì—°ê²°í•˜ê¸° ìœ„í•¨) ---

def upload_wrapper(file, progress=gr.Progress(track_tqdm=True)):
    """upload_fileì— DATA_DIRì„ ì „ë‹¬í•˜ê³  Gradio í”„ë¡œê·¸ë ˆìŠ¤ ë°”ë¥¼ í™œì„±í™”í•˜ëŠ” ë˜í¼ í•¨ìˆ˜"""
    return upload_file(file, DATA_DIR, progress)

def save_recording_wrapper(temp_file, fname):
    """save_recordingì— DATA_DIRì„ ì „ë‹¬í•˜ê¸° ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    return save_recording(temp_file, fname, DATA_DIR)

# --- Gradio ì½œë°± í•¨ìˆ˜ (ì‚¬ìš©ì í–‰ë™ì— ë°˜ì‘í•˜ëŠ” í•¨ìˆ˜ë“¤) ---

def run_processing_and_update_ui(audio_filename, llm_choice, topic, keywords_str, progress=gr.Progress(track_tqdm=True)):
    """ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³  UIë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    if not audio_filename:
        return "ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.", "", "", gr.Dropdown(choices=[name for name, _ in get_processed_meetings()]), {}

    progress(0, desc="ì¤€ë¹„ ì¤‘...")
    audio_path = os.path.join(DATA_DIR, audio_filename)
    keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]

    results_path, message = run_pipeline(audio_path, llm_choice, topic, keywords)
    progress(0.9, desc="ê²°ê³¼ íŒŒì¼ ë¡œë”© ì¤‘...")

    if not results_path:
        return f"**ì²˜ë¦¬ ì‹¤íŒ¨:** {message}", "", "", gr.Dropdown(choices=[name for name, _ in get_processed_meetings()]), {}

    summary_markdown = "ìš”ì•½ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    corrected_text = "êµì •ëœ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    try:
        base_filename = os.path.splitext(audio_filename)[0]
        summary_path = os.path.join(results_path, f"summary_{base_filename}.md")
        corrected_path = os.path.join(results_path, f"corrected_{base_filename}.txt")
        
        with open(summary_path, 'r', encoding='utf-8') as f:
            summary_json_str = f.read()
            summary_markdown = format_summary_json_to_markdown(summary_json_str)

        with open(corrected_path, 'r', encoding='utf-8') as f:
            corrected_text = f.read()
    except Exception as e:
        logging.error(f"ê²°ê³¼ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        message += f"\nê²°ê³¼ íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    progress(1, desc="ì™„ë£Œ")
    new_meetings = get_processed_meetings()
    return f"**{message}** ê²°ê³¼ëŠ” '{results_path}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", summary_markdown, corrected_text, gr.Dropdown(choices=[name for name, _ in new_meetings]), dict(new_meetings)

def handle_chat_message(user_question, history, collection_name):
    """ì±—ë´‡ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. (messages í¬ë§·)"""
    if not collection_name:
        history.append({"role": "user", "content": user_question})
        history.append({"role": "assistant", "content": "ë¨¼ì € ì¢Œì¸¡ ìƒë‹¨ì—ì„œ ëŒ€í™”í•  íšŒì˜ë¡ì„ ì„ íƒí•´ì£¼ì„¸ìš”."})
        return history, ""
        
    history.append({"role": "user", "content": user_question})
    yield history, ""

    response = run_query(user_question, collection_name)
    history.append({"role": "assistant", "content": response})
    yield history, ""

# --- Q&A íƒ­ ì½œë°± í•¨ìˆ˜ ---

# í™”ìë³„ ì•„ì´ì½˜ ë¦¬ìŠ¤íŠ¸ (ì´ëª¨ì§€)
SPEAKER_ICONS = ["ğŸ˜€", "ğŸ˜", "ğŸ˜Š", "ğŸ§‘", "ğŸ‘©", "ğŸ¤”", "ğŸ¤“", "ğŸ¤–"]

def load_meeting_data(selection, state):
    """ë“œë¡­ë‹¤ìš´ì—ì„œ íšŒì˜ë¡ ì„ íƒ ì‹œ ìš”ì•½ê³¼ ëŒ€í™”ë¡ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not selection:
        return gr.update(value=None), gr.update(value=None), None

    # 1. íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
    base_filename = '_'.join(selection.split('_')[:-1])
    results_folder_path = os.path.join(RESULTS_DIR, selection)
    summary_path = os.path.join(results_folder_path, f"summary_{base_filename}.md")
    corrected_path = os.path.join(results_folder_path, f"corrected_{base_filename}.txt")

    # 2. ìš”ì•½ íŒŒì¼ ì½ê³  ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
    summary_markdown = "ìš”ì•½ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    try:
        with open(summary_path, 'r', encoding='utf-8') as f:
            summary_json_str = f.read()
            summary_markdown = format_summary_json_to_markdown(summary_json_str)
    except FileNotFoundError:
        logging.warning(f"ìš”ì•½ íŒŒì¼ ì—†ìŒ: {summary_path}")
    except Exception as e:
        logging.error(f"ìš”ì•½ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    # 3. ëŒ€í™”ë¡ íŒŒì¼ ì½ê³  íŒŒì‹±í•˜ê¸° (chat.png UI ì²˜ëŸ¼)
    transcript_chat_history = []
    speaker_icon_map = {}
    icon_index = 0
    try:
        with open(corrected_path, 'r', encoding='utf-8') as f:
            full_text = f.read() # íŒŒì¼ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì½ê¸°
        
        lines = full_text.split('\n') # ë¬¸ìì—´ì„ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¦¬ìŠ¤íŠ¸ ìƒì„±

        for line in lines:
            if not line.strip(): # ë¹ˆ ì¤„ì€ ê±´ë„ˆë›°ê¸°
                continue

            match = re.search(r'\\[.*?s - .*?s\\]\s*(.*?):\s*(.*)', line)
            if match:
                speaker, text = match.groups()
                speaker = speaker.strip()
                
                # ìƒˆë¡œìš´ í™”ìì¼ ê²½ìš°, ì•„ì´ì½˜ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì•„ì´ì½˜ í• ë‹¹
                if speaker not in speaker_icon_map:
                    speaker_icon_map[speaker] = SPEAKER_ICONS[icon_index % len(SPEAKER_ICONS)]
                    icon_index += 1
                
                icon = speaker_icon_map[speaker]
                
                # ì•„ì´ì½˜, í™”ì ì´ë¦„, ëŒ€í™” ë‚´ìš©ì„ í¬í•¨í•˜ëŠ” ì™¼ìª½ ì •ë ¬ ë§í’ì„  ìƒì„±
                chat_message = f"{icon} **{speaker}**\n{text.strip()}"
                transcript_chat_history.append((chat_message, None))
            else:
                transcript_chat_history.append((line.strip(), None))
    except FileNotFoundError:
        logging.warning(f"ëŒ€í™”ë¡ íŒŒì¼ ì—†ìŒ: {corrected_path}")
        transcript_chat_history = [("ëŒ€í™”ë¡ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None)]
    except Exception as e:
        logging.error(f"ëŒ€í™”ë¡ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        transcript_chat_history = [("ëŒ€í™”ë¡ íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: " + str(e), None)]

    # 4. Collection ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    collection_name = state.get(selection)

    return summary_markdown, transcript_chat_history, collection_name

def refresh_chatbot_dropdown():
    new_meetings = get_processed_meetings()
    return gr.Dropdown(choices=[name for name, _ in new_meetings]), dict(new_meetings)
